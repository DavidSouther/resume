<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/5f300098a6190bc2.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/011494695c542565.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-74754c1a456c813c.js"/><script src="/_next/static/chunks/4bd1b696-c3879825879d57b8.js" async=""></script><script src="/_next/static/chunks/517-246481c1c41bb581.js" async=""></script><script src="/_next/static/chunks/main-app-25b9ca2f33262242.js" async=""></script><script src="/_next/static/chunks/829-341774b777d6f278.js" async=""></script><script src="/_next/static/chunks/app/layout-2963253080626e5a.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bid%5D/page-1ba1c95a36064a59.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-6X1Z1L95D8" as="script"/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"/><title>Beyond Knowledge-That: LLMs&#x27; Indirect Understanding - David Souther</title><meta name="description" content="davidsouther.com - resume, blog, playground"/><link rel="author" href="davidsouther.com"/><meta name="author" content="David Souther"/><link rel="manifest" href="/manifest.json"/><meta property="og:title" content="Beyond Knowledge-That: LLMs&#x27; Indirect Understanding - David Souther"/><meta property="og:description" content="davidsouther.com - resume, blog, playground"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Beyond Knowledge-That: LLMs&#x27; Indirect Understanding - David Souther"/><meta name="twitter:description" content="davidsouther.com - resume, blog, playground"/><link rel="stylesheet" href="/jiffies-css-bundle.min.css"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="container"><article class="blog-page_BlogPage__t8vJA"><header><h3><a href="/">David Souther</a> - <!-- -->Beyond Knowledge-That: LLMs&#x27; Indirect Understanding<!-- --> - <!-- -->2024-04-17</h3></header><main><div><p>Why I Can Say &quot;The AI Knows&quot; but Still Claim &quot;It Doesn&#39;t Really Know&quot;?</p>
<p>We often talk about AI language models like they have real knowledge: &quot;ChatGPT said the capital of France is Paris&quot; or &quot;Claude knows a lot about quantum physics.&quot; But then we also say things like &quot;Language models don&#39;t actually understand what they&#39;re saying&quot; or &quot;They have no real knowledge, just patterns in data.&quot;</p>
<p>This seems like a contradiction, but there&#39;s actually a useful philosophical distinction that can resolve it. The philosopher Bertrand Russell drew a line between two types of knowledge:</p>
<ul>
<li><em>Knowledge-that</em>: This is factual, descriptive knowledge that can be stated in propositions or truth claims. Think &quot;book smarts.&quot;</li>
<li><em>Knowledge-by</em>: This is experiential, first-hand knowledge gained through direct acquaintance or immersion. The &quot;street smarts&quot; version.</li>
</ul>
<p>But there&#39;s a third type of knowledge that doesn&#39;t quite fit into Russell&#39;s framing:</p>
<ul>
<li><em>Knowledge-of</em>: Second-hand knowledge gained indirectly through conveyances like text and conversation rather than genuine experience.</li>
</ul>
<p>Language models like Claude have plenty of knowledge-of. Their training process exposes them to a vast trove of information extracted from the human-written text used as training . So when Claude tells you about the Napoleonic Wars or answers a coding question, it&#39;s drawing upon this second-hand knowledge-of.</p>
<p>Crucially, though, the AI doesn&#39;t have the grounded, experiential knowledge-by that a human historian or programmer would have. It also lacks the conceptual, justified true belief that comprises genuine knowledge-that. This lack of knowledge-that, combined with the requirement to generate syntactically correct language, is what leads the model to hallucinate.</p>
<p>Language serves to encode and transmit knowledge-that and knowledge-by between genuinely knowledgeable agents—people like you and me. AI, on the other hand, operates purely on the knowledge-of level--extracting apparent knowledge from linguistic patterns without the underlying semantics.</p>
<p>So while we can imprecisely say an AI“ knows&quot; things in the sense of knowledge-of, it lacks true knowledge-that and certainly lacks knowledge-by. Its knowledge is second-hand, derived from linguistic representations of reality and not genuine understanding.</p>
<p>That&#39;s why I can honestly claim both &quot;the AI knows&quot; and &quot;it doesn&#39;t actually know&quot; without contradicting myself. What it &quot;knows&quot; is mere knowledge-of, not the real thing. Keeping this distinction in mind helps clarify what capabilities language models do and don&#39;t actually possess.</p>
</div></main><footer><a href="../../">Back</a></footer></article><script src="/_next/static/chunks/webpack-74754c1a456c813c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[5244,[],\"\"]\n3:I[3866,[],\"\"]\n4:I[379,[\"829\",\"static/chunks/829-341774b777d6f278.js\",\"177\",\"static/chunks/app/layout-2963253080626e5a.js\"],\"default\"]\n6:I[6213,[],\"OutletBoundary\"]\n8:I[6213,[],\"MetadataBoundary\"]\na:I[6213,[],\"ViewportBoundary\"]\nc:I[4835,[],\"\"]\n:HL[\"/_next/static/css/5f300098a6190bc2.css\",\"style\"]\n:HL[\"/_next/static/css/011494695c542565.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"xZ_dp1MVIBBHBHV7F5Aso\",\"p\":\"\",\"c\":[\"\",\"blog\",\"knowledge_that_by_of\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"id\",\"knowledge_that_by_of\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/5f300098a6190bc2.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"/jiffies-css-bundle.min.css\"}]}],[\"$\",\"body\",null,{\"className\":\"container\",\"children\":[[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"$L4\",null,{}]]}]]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"id\",\"knowledge_that_by_of\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/011494695c542565.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":\"$L7\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"ooQDQojPaYc5ZkB-fxwLJ\",{\"children\":[[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],null]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$c\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"d:I[973,[\"567\",\"static/chunks/app/blog/%5Bid%5D/page-1ba1c95a36064a59.js\"],\"Card\"]\ne:Tb31,"])</script><script>self.__next_f.push([1,"\u003cp\u003eWhy I Can Say \u0026quot;The AI Knows\u0026quot; but Still Claim \u0026quot;It Doesn\u0026#39;t Really Know\u0026quot;?\u003c/p\u003e\n\u003cp\u003eWe often talk about AI language models like they have real knowledge: \u0026quot;ChatGPT said the capital of France is Paris\u0026quot; or \u0026quot;Claude knows a lot about quantum physics.\u0026quot; But then we also say things like \u0026quot;Language models don\u0026#39;t actually understand what they\u0026#39;re saying\u0026quot; or \u0026quot;They have no real knowledge, just patterns in data.\u0026quot;\u003c/p\u003e\n\u003cp\u003eThis seems like a contradiction, but there\u0026#39;s actually a useful philosophical distinction that can resolve it. The philosopher Bertrand Russell drew a line between two types of knowledge:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eKnowledge-that\u003c/em\u003e: This is factual, descriptive knowledge that can be stated in propositions or truth claims. Think \u0026quot;book smarts.\u0026quot;\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eKnowledge-by\u003c/em\u003e: This is experiential, first-hand knowledge gained through direct acquaintance or immersion. The \u0026quot;street smarts\u0026quot; version.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBut there\u0026#39;s a third type of knowledge that doesn\u0026#39;t quite fit into Russell\u0026#39;s framing:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eKnowledge-of\u003c/em\u003e: Second-hand knowledge gained indirectly through conveyances like text and conversation rather than genuine experience.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLanguage models like Claude have plenty of knowledge-of. Their training process exposes them to a vast trove of information extracted from the human-written text used as training . So when Claude tells you about the Napoleonic Wars or answers a coding question, it\u0026#39;s drawing upon this second-hand knowledge-of.\u003c/p\u003e\n\u003cp\u003eCrucially, though, the AI doesn\u0026#39;t have the grounded, experiential knowledge-by that a human historian or programmer would have. It also lacks the conceptual, justified true belief that comprises genuine knowledge-that. This lack of knowledge-that, combined with the requirement to generate syntactically correct language, is what leads the model to hallucinate.\u003c/p\u003e\n\u003cp\u003eLanguage serves to encode and transmit knowledge-that and knowledge-by between genuinely knowledgeable agents—people like you and me. AI, on the other hand, operates purely on the knowledge-of level--extracting apparent knowledge from linguistic patterns without the underlying semantics.\u003c/p\u003e\n\u003cp\u003eSo while we can imprecisely say an AI“ knows\u0026quot; things in the sense of knowledge-of, it lacks true knowledge-that and certainly lacks knowledge-by. Its knowledge is second-hand, derived from linguistic representations of reality and not genuine understanding.\u003c/p\u003e\n\u003cp\u003eThat\u0026#39;s why I can honestly claim both \u0026quot;the AI knows\u0026quot; and \u0026quot;it doesn\u0026#39;t actually know\u0026quot; without contradicting myself. What it \u0026quot;knows\u0026quot; is mere knowledge-of, not the real thing. Keeping this distinction in mind helps clarify what capabilities language models do and don\u0026#39;t actually possess.\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"$Ld\",null,{\"header\":[[\"$\",\"a\",null,{\"href\":\"/\",\"children\":\"David Souther\"}],\" - \",\"Beyond Knowledge-That: LLMs' Indirect Understanding\",\" - \",\"2024-04-17\"],\"footer\":[\"$\",\"a\",null,{\"href\":\"../../\",\"children\":\"Back\"}],\"className\":\"blog-page_BlogPage__t8vJA\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"name\":\"theme-color\",\"media\":\"(prefers-color-scheme: light)\",\"content\":\"white\"}],[\"$\",\"meta\",\"2\",{\"name\":\"theme-color\",\"media\":\"(prefers-color-scheme: dark)\",\"content\":\"black\"}]]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Beyond Knowledge-That: LLMs' Indirect Understanding - David Souther\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"davidsouther.com - resume, blog, playground\"}],[\"$\",\"link\",\"3\",{\"rel\":\"author\",\"href\":\"davidsouther.com\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"David Souther\"}],[\"$\",\"link\",\"5\",{\"rel\":\"manifest\",\"href\":\"/manifest.json\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Beyond Knowledge-That: LLMs' Indirect Understanding - David Souther\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"davidsouther.com - resume, blog, playground\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:title\",\"content\":\"Beyond Knowledge-That: LLMs' Indirect Understanding - David Souther\"}],[\"$\",\"meta\",\"10\",{\"name\":\"twitter:description\",\"content\":\"davidsouther.com - resume, blog, playground\"}]]\n"])</script><script>self.__next_f.push([1,"7:null\n"])</script></body></html>